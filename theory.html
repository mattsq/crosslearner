<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Theoretical Background &#8212; crosslearner 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <script src="_static/documentation_options.js?v=2709fde1"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Hyperparameter Sweeps with Optuna" href="hyperparameter_sweeps.html" />
    <link rel="prev" title="crosslearner documentation" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="theoretical-background">
<h1>Theoretical Background<a class="headerlink" href="#theoretical-background" title="Link to this heading">¶</a></h1>
<p>AC-X builds on two key ideas in modern causal inference: the X-learner
meta-approach and the DragonNet architecture.  The X-learner imputes
counterfactual outcomes from separate models for the treated and
control groups, producing pseudo-outcomes that can be used to learn a
final treatment effect estimator.  DragonNet in contrast trains a
single neural network with shared representations and an auxiliary
propensity head.  Its objective ties the potential outcome heads
together through regularisation based on treatment probability.</p>
<p>AC-X combines these perspectives.  The network resembles a simplified
DragonNet with explicit potential outcome heads and a separate
treatment-effect head.  It still follows the X-learner philosophy of
borrowing the opposite arm’s prediction as a pseudo-outcome, but all
components are trained jointly so that gradients from the
consistency and adversarial terms update both outcome heads and the
shared representation.</p>
<section id="benefits-of-adversarial-training">
<h2>Benefits of Adversarial Training<a class="headerlink" href="#benefits-of-adversarial-training" title="Link to this heading">¶</a></h2>
<p>Enforcing an adversarial game between a generator (the potential
outcome models) and a discriminator helps the model learn
counterfactuals that are indistinguishable from real observations.
This adversarial signal provides useful gradients even when overlap is
limited, acting as an implicit regulariser and reducing bias from
covariate imbalance.  Empirically, adversarial training tends to lower
root PEHE and encourages smoother treatment-effect surfaces.</p>
</section>
<section id="ac-x-training-procedure">
<h2>AC-X Training Procedure<a class="headerlink" href="#ac-x-training-procedure" title="Link to this heading">¶</a></h2>
<p>The following pseudocode sketches the training loop implemented in
<a class="reference internal" href="api/crosslearner.training.html#module-crosslearner.training.train_acx" title="crosslearner.training.train_acx"><code class="xref py py-mod docutils literal notranslate"><span class="pre">crosslearner.training.train_acx</span></code></a>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>initialise AC-X model and optimisers
for each epoch:
    for each batch (X, T, Y):
        # update discriminator
        h, m0, m1, _ = model(X)
        Y_cf = where(T == 1, m0, m1)
        real_logits = discriminator(h, Y, T)
        fake_logits = discriminator(h, Y_cf, T)
        loss_d = adv_loss(real_logits, fake_logits)
        backprop and update discriminator

        # update generator
        h, m0, m1, tau = model(X)
        m_obs = where(T == 1, m1, m0)
        loss_y = mse(m_obs, Y)
        loss_cons = mse(tau, m1 - m0)
        Y_cf = where(T == 1, m0, m1)
        fake_logits = discriminator(h, Y_cf, T)
        loss_adv = generator_adv_loss(fake_logits)
        loss_g = alpha_out * loss_y + beta_cons * loss_cons + gamma_adv * loss_adv
        backprop and update generator

return trained model
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">crosslearner</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Theoretical Background</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#benefits-of-adversarial-training">Benefits of Adversarial Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ac-x-training-procedure">AC-X Training Procedure</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter_sweeps.html">Hyperparameter Sweeps with Optuna</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage_examples.html">Usage Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">crosslearner</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">crosslearner documentation</a></li>
      <li>Next: <a href="hyperparameter_sweeps.html" title="next chapter">Hyperparameter Sweeps with Optuna</a></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Matthew Simmons.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/theory.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>